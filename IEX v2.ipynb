{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbetc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dbetc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dbetc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "pandas.set_option('display.max_columns',None)\n",
    "pandas.set_option('display.max_rows',None)\n",
    "import requests\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy\n",
    "\n",
    "portfolio_list = ['ACB','AMD','CCL','COST','CX','DIS','FANG',\n",
    "              'GE','GRUB','MTCH','NLY','OKE',\n",
    "              'PLD','PYPL','RBLX','SQ','TDOC','TSLA',\n",
    "              'WWE','DNMR','BMBL','SHOP','WMT','TGT','EBAY',\n",
    "              'CRSP','NKLA','LYB','RIO','IP','COP']\n",
    "\n",
    "all_tickers = pandas.read_csv('stock_ticker_info.csv')\n",
    "\n",
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "# List Refinement #\n",
    "\n",
    "focus_list = pandas.merge(pandas.DataFrame(portfolio_list,columns=['Ticker']),all_tickers,on='Ticker')[['Ticker','Name','Sector','Industry']]\n",
    "sectors = focus_list['Sector'].unique()\n",
    "industries = focus_list['Industry'].unique()\n",
    "ticker_list = all_tickers[all_tickers['Industry'].isin(industries)]#['Ticker'].to_list()\n",
    "ticker_list['key'] = ticker_list.Market_Cap.str.replace(r\"[0-9/./()]\",'')\n",
    "ticker_list['value'] = pandas.to_numeric(ticker_list.Market_Cap.str.replace(r\"[^0-9/^./^()]\",''))\n",
    "ticker_list['New_Market_Cap'] = numpy.where(ticker_list['key']=='-',0,\n",
    "                                   numpy.where(ticker_list['key']=='B',\n",
    "                                   ticker_list['value']*1000000000,\n",
    "                                   ticker_list['value']*1000000))\n",
    "# greater than 10 Billion Market Cap or original list\n",
    "ticker_df = ticker_list\n",
    "ticker_list = ticker_list[(ticker_list['New_Market_Cap']>10000000000) | (ticker_list['Ticker'].isin(portfolio_list))]['Ticker'].to_list()\n",
    "rejoin_df = pandas.DataFrame(ticker_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper to get all stock tickers in US markets\n",
    "### Only need to run when refreshing the list (only to capture new listings, ipos, directs, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finviz_df = pandas.DataFrame()\n",
    "# mylist = range(1,8000)\n",
    "\n",
    "# for count in mylist[::20]:\n",
    "#     url = \"https://finviz.com/screener.ashx?v=111&r=\"+str(count)\n",
    "#     finviz = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "#     fin_table = pandas.read_html(str(finviz.find_all(\"table\")[13]))\n",
    "#     fin_table = fin_table[3].dropna(axis=0, thresh=4)\n",
    "#     finviz_df = pandas.concat([finviz_df,fin_table],axis=0,sort=True)\n",
    "\n",
    "\n",
    "# finviz_df.columns = ['Row','Ticker','Name','Sector','Industry','Country','Market_Cap','Current_P/E','Current_Price','Day_Chg','Current_Vol']\n",
    "# finviz_df = finviz_df.drop(finviz_df[finviz_df.Ticker == 'Ticker'].index)\n",
    "# finviz_df = finviz_df.drop_duplicates()\n",
    "# finviz_df.to_csv('stock_ticker_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper for Stock Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_df = pandas.DataFrame()\n",
    "table1_df = pandas.DataFrame()\n",
    "\n",
    "for symbol in ticker_list:\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials/balance-sheet\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        table2 = pandas.read_html(str(marketwatch.find_all(\"table\")[5]))\n",
    "        table2 = table2[0].dropna(axis=0, thresh=4)\n",
    "        table2['ticker'] = symbol\n",
    "        table2['PeriodType'] = 'Annual'\n",
    "        table2_df = pandas.concat([table2_df,table2],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table1 = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        table1 = table1[0].dropna(axis=0, thresh=4)\n",
    "        table1['ticker'] = symbol\n",
    "        table1['PeriodType'] = 'Annual'\n",
    "        table1_df = pandas.concat([table1_df,table1],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials/balance-sheet/quarter\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        table2 = pandas.read_html(str(marketwatch.find_all(\"table\")[5]))\n",
    "        table2 = table2[0].dropna(axis=0, thresh=4)\n",
    "        table2['ticker'] = symbol\n",
    "        table2['PeriodType'] = 'Quarterly'\n",
    "        table2_df = pandas.concat([table2_df,table2],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table1 = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        table1 = table1[0].dropna(axis=0, thresh=4)\n",
    "        table1['ticker'] = symbol\n",
    "        table1['PeriodType'] = 'Quarterly'\n",
    "        table1_df = pandas.concat([table1_df,table1],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "balance_sheets = pandas.concat([table2_df,table1_df],sort=True)\n",
    "balance_sheets = pandas.melt(balance_sheets, id_vars=['Item Item','ticker','PeriodType'])\n",
    "balance_sheets.columns = ['LineItem','Ticker','PeriodType','Period','Value']\n",
    "balance_sheets = balance_sheets.dropna()\n",
    "balance_sheets['Length'] = balance_sheets['Value'].str.len()\n",
    "balance_sheets = balance_sheets.assign(Multiplier=balance_sheets.apply(lambda x: x['Value'][x['Length']-1:], axis=1))\n",
    "balance_sheets['Neg'] = numpy.where(balance_sheets['Multiplier'] == ')','yes','no')\n",
    "balance_sheets['key'] = balance_sheets.Value.str.replace(r\"[0-9/./()]\",'')\n",
    "balance_sheets['Stripped_Value'] = balance_sheets.Value.str.replace(r\"[^\\d.]\",'')\n",
    "balance_sheets['Stripped_Value'] = pandas.to_numeric(balance_sheets['Stripped_Value'])\n",
    "balance_sheets['Real_Value'] = numpy.where(balance_sheets.key=='B',balance_sheets['Stripped_Value']*1000000000,\n",
    "                                           numpy.where(balance_sheets.key=='M',balance_sheets['Stripped_Value']*1000000,\n",
    "                                                 numpy.where(balance_sheets.key=='K',balance_sheets['Stripped_Value']*1000,\n",
    "                                                       numpy.where(balance_sheets.key=='%',balance_sheets['Stripped_Value']/100,\n",
    "                                                             numpy.where(balance_sheets.key=='-%',balance_sheets['Stripped_Value']/-100,\n",
    "                                                                   numpy.where(balance_sheets.key=='',balance_sheets['Stripped_Value'],\n",
    "                                                                               numpy.where(balance_sheets.key=='-',balance_sheets['Stripped_Value'],\n",
    "                                                                                           numpy.where(balance_sheets.key=='T',balance_sheets['Stripped_Value']*1000000000000,0))))))))\n",
    "balance_sheets['Real_Value'] = numpy.where(balance_sheets.Neg=='yes',(balance_sheets['Real_Value']*-1)/1000000,balance_sheets['Real_Value']/1000000)\n",
    "balance_sheets = balance_sheets[(['LineItem','Ticker','PeriodType','Period','Real_Value'])]\n",
    "balance_sheets = balance_sheets.pivot_table(index=(['Period','Ticker','PeriodType']), columns='LineItem', values='Real_Value').reset_index()\n",
    "\n",
    "asset_df = pandas.DataFrame()\n",
    "\n",
    "for symbol in ticker_list:\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        assets = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        assets = assets[0].dropna(axis=0, thresh=4)\n",
    "        assets['ticker'] = symbol\n",
    "        assets['PeriodType'] = 'Annual'\n",
    "        asset_df = pandas.concat([asset_df,assets],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials/income/quarter\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url).text,\"lxml\")\n",
    "    try:\n",
    "        assets = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        assets = assets[0].dropna(axis=0, thresh=4)\n",
    "        assets['ticker'] = symbol\n",
    "        assets['PeriodType'] = 'Quarterly'\n",
    "        asset_df = pandas.concat([asset_df,assets],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "income = asset_df\n",
    "income = pandas.melt(income, id_vars=['Item Item','ticker','PeriodType'])\n",
    "income.columns = ['LineItem','Ticker','PeriodType','Period','Value']\n",
    "income = income.dropna()\n",
    "income['Length'] = income['Value'].str.len()\n",
    "income = income.assign(Multiplier=income.apply(lambda x: x['Value'][x['Length']-1:], axis=1))\n",
    "income['Neg'] = numpy.where(income['Multiplier'] == ')','yes','no')\n",
    "income['key'] = income.Value.str.replace(r\"[0-9/./()]\",'')\n",
    "income['Stripped_Value'] = income.Value.str.replace(r\"[^\\d.]\",'')\n",
    "income['Stripped_Value'] = pandas.to_numeric(income['Stripped_Value'])\n",
    "income['Real_Value'] = numpy.where(income.key=='B',income['Stripped_Value']*1000000000,\n",
    "                                           numpy.where(income.key=='M',income['Stripped_Value']*1000000,\n",
    "                                                 numpy.where(income.key=='K',income['Stripped_Value']*1000,\n",
    "                                                       numpy.where(income.key=='%',income['Stripped_Value']/100,\n",
    "                                                             numpy.where(income.key=='-%',income['Stripped_Value']/-100,\n",
    "                                                                   numpy.where(income.key=='',income['Stripped_Value'],\n",
    "                                                                               numpy.where(income.key=='-',income['Stripped_Value'],\n",
    "                                                                                           numpy.where(income.key=='T',income['Stripped_Value']*1000000000000,0))))))))\n",
    "income['Real_Value'] = numpy.where(income.Neg=='yes',(income['Real_Value']*-1)/1000000,income['Real_Value']/1000000)\n",
    "income = income[(['LineItem','Ticker','PeriodType','Period','Real_Value'])]\n",
    "income = income.pivot_table(index=(['Period','Ticker','PeriodType']), columns='LineItem', values='Real_Value').reset_index()\n",
    "\n",
    "table2_df = pandas.DataFrame()\n",
    "table1_df = pandas.DataFrame()\n",
    "table3_df = pandas.DataFrame()\n",
    "\n",
    "for symbol in ticker_list:\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials/cash-flow\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        table2 = pandas.read_html(str(marketwatch.find_all(\"table\")[5]))\n",
    "        table2 = table2[0].dropna(axis=0, thresh=4)\n",
    "        table2['ticker'] = symbol\n",
    "        table2['PeriodType'] = 'Annual'\n",
    "        table2_df = pandas.concat([table2_df,table2],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table1 = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        table1 = table1[0].dropna(axis=0, thresh=4)\n",
    "        table1['ticker'] = symbol\n",
    "        table1['PeriodType'] = 'Annual'\n",
    "        table1_df = pandas.concat([table1_df,table1],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table3 = pandas.read_html(str(marketwatch.find_all(\"table\")[6]))\n",
    "        table3 = table3[0].dropna(axis=0, thresh=4)\n",
    "        table3['ticker'] = symbol\n",
    "        table3['PeriodType'] = 'Annual'\n",
    "        table3_df = pandas.concat([table3_df,table3],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/financials/cash-flow/quarter\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        table2 = pandas.read_html(str(marketwatch.find_all(\"table\")[5]))\n",
    "        table2 = table2[0].dropna(axis=0, thresh=4)\n",
    "        table2['ticker'] = symbol\n",
    "        table2['PeriodType'] = 'Quarterly'\n",
    "        table2_df = pandas.concat([table2_df,table2],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table1 = pandas.read_html(str(marketwatch.find_all(\"table\")[4]))\n",
    "        table1 = table1[0].dropna(axis=0, thresh=4)\n",
    "        table1['ticker'] = symbol\n",
    "        table1['PeriodType'] = 'Quarterly'\n",
    "        table1_df = pandas.concat([table1_df,table1],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table3 = pandas.read_html(str(marketwatch.find_all(\"table\")[6]))\n",
    "        table3 = table3[0].dropna(axis=0, thresh=4)\n",
    "        table3['ticker'] = symbol\n",
    "        table3['PeriodType'] = 'Quarterly'\n",
    "        table3_df = pandas.concat([table3_df,table3],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "cash_flow = pandas.concat([pandas.concat([table2_df,table1_df],sort=True),table3_df],sort=True)\n",
    "cash_flow = pandas.melt(cash_flow, id_vars=['Item Item','ticker','PeriodType'])\n",
    "cash_flow.columns = ['LineItem','Ticker','PeriodType','Period','Value']\n",
    "cash_flow = cash_flow.dropna()\n",
    "cash_flow['Length'] = cash_flow['Value'].str.len()\n",
    "cash_flow = cash_flow.assign(Multiplier=cash_flow.apply(lambda x: x['Value'][x['Length']-1:], axis=1))\n",
    "cash_flow['Neg'] = numpy.where(cash_flow['Multiplier'] == ')','yes','no')\n",
    "cash_flow['key'] = cash_flow.Value.str.replace(r\"[0-9/./()]\",'')\n",
    "cash_flow['Stripped_Value'] = cash_flow.Value.str.replace(r\"[^\\d.]\",'')\n",
    "cash_flow['Stripped_Value'] = pandas.to_numeric(cash_flow['Stripped_Value'])\n",
    "cash_flow['Real_Value'] = numpy.where(cash_flow.key=='B',cash_flow['Stripped_Value']*1000000000,\n",
    "                                           numpy.where(cash_flow.key=='M',cash_flow['Stripped_Value']*1000000,\n",
    "                                                 numpy.where(cash_flow.key=='K',cash_flow['Stripped_Value']*1000,\n",
    "                                                       numpy.where(cash_flow.key=='%',cash_flow['Stripped_Value']/100,\n",
    "                                                             numpy.where(cash_flow.key=='-%',cash_flow['Stripped_Value']/-100,\n",
    "                                                                   numpy.where(cash_flow.key=='',cash_flow['Stripped_Value'],\n",
    "                                                                               numpy.where(cash_flow.key=='-',cash_flow['Stripped_Value'],\n",
    "                                                                                           numpy.where(cash_flow.key=='T',cash_flow['Stripped_Value']*1000000000000,0))))))))\n",
    "cash_flow['Real_Value'] = numpy.where(cash_flow.Neg=='yes',(cash_flow['Real_Value']*-1)/1000000,cash_flow['Real_Value']/1000000)\n",
    "cash_flow = cash_flow[(['LineItem','Ticker','PeriodType','Period','Real_Value'])]\n",
    "cash_flow = cash_flow.pivot_table(index=(['Period','Ticker','PeriodType']), columns='LineItem', values='Real_Value').reset_index()\n",
    "\n",
    "final = pandas.merge(pandas.merge(balance_sheets,income,on=['Period','Ticker']),cash_flow,on=['Period','Ticker'])\n",
    "final['Period'] = pandas.to_datetime(final['Period'])\n",
    "final = final.fillna(0)\n",
    "final['Update'] = pandas.Timestamp.now()\n",
    "final = pandas.merge(final,ticker_df,how='left',on='Ticker')\n",
    "\n",
    "# final.to_csv('stock_financials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper for Analyst Opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_df = pandas.DataFrame()\n",
    "table1_df = pandas.DataFrame()\n",
    "\n",
    "for symbol in ticker_list:\n",
    "    url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/analystestimates?mod=mw_quote_tab\"\n",
    "    marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "    try:\n",
    "        table2 = pandas.read_html(str(marketwatch.find_all(\"table\")[7]))\n",
    "        table2 = table2[0].dropna(axis=0, thresh=4)\n",
    "        table2['ticker'] = symbol\n",
    "        table2_df = pandas.concat([table2_df,table2],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        table1 = pandas.read_html(str(marketwatch.find_all(\"table\")[9]))\n",
    "        table1 = table1[0].dropna(axis=0, thresh=4)\n",
    "        table1['ticker'] = symbol\n",
    "        table1_df = pandas.concat([table1_df,table1],axis=0,sort=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "analysts = pandas.concat([table2_df,table1_df],sort=True)\n",
    "analysts = pandas.melt(analysts, id_vars=['Unnamed: 0','ticker'])\n",
    "analysts.columns = ['Category','Ticker','Period','Value']\n",
    "analysts = analysts.dropna()\n",
    "analysts = analysts[(['Category','Ticker','Period','Value'])]\n",
    "analysts = analysts.set_index('Category')\n",
    "analysts = analysts.pivot_table(index=(['Period','Ticker']), columns='Category', values='Value',aggfunc='first').reset_index()\n",
    "\n",
    "analysts.to_csv('stock_analysts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old scraper template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty = []\n",
    "\n",
    "# for symbol in ticker_list:\n",
    "#     try:\n",
    "#         url = \"https://www.marketwatch.com/investing/stock/\"+symbol+\"/company-profile?mod=mw_quote_tab\"\n",
    "#         marketwatch = BeautifulSoup(requests.get(url,headers=headers,allow_redirects=False).text,\"lxml\")\n",
    "#         ind = marketwatch.find_all('span',{'primary'})[6].text\n",
    "#         sec = marketwatch.find_all('span',{'primary'})[7].text\n",
    "#         empty.append([symbol,ind,sec])\n",
    "#     except Exception:\n",
    "#         pass\n",
    "# stock_info = pandas.DataFrame(empty,columns=['Ticker','Industry','Sector'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
